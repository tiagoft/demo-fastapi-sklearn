{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from tqdm import tqdm\n",
    "\n",
    "from langchain.schema import Document\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n",
    "url_video = 'https://www.youtube.com/watch?v=0NBL7sNOLoM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    loader = YoutubeLoader.from_youtube_url(\n",
    "        url_video, add_video_info=True, language=['pt']\n",
    "    )\n",
    "    transcript = loader.load()\n",
    "except:\n",
    "    print('Erro no vídeo: ', url_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = transcript[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ok pessoal thago falando e neste vídeo eu vou dar algumas anotações sobre '\n",
      " 'como que a gente pode organizar um projeto baseado em dados e fazer o Deploy '\n",
      " 'de um sisteminha de é predição né baseado em dado')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(content[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    Document\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "system = \"\"\"Você é um assitente prestativo que irá utilizar a transcrição de um vídeo no Youtube feito pelo professor Tiago Tavares para criar o README do repositório da FASTAPI que ele cita no próprio vídeo. Portanto, traga conteúdo chave do vídeo, destacando o que é importante para os alunos. \n",
    "\n",
    "Obs.: Dê destaque ao fato de que o professor Tiago Tavares quis ajudar os alunos que estavam fazendo o .fit() do modelo direto na função das queries, o que gera um problema de performace.\n",
    "\n",
    "Por fim, traga num formato padrão de README!\n",
    "\"\"\"\n",
    "            \n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        \n",
    "        (\"human\", \"Trancrição do vídeo: {transcript}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({'transcript': content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# FastAPI Sentiment Analysis\n",
      "\n",
      "Este repositório contém um exemplo de como organizar um projeto de análise de sentimentos utilizando FastAPI para criar uma API de predição. O objetivo é demonstrar como fazer o deploy de um modelo de machine learning treinado para análise de sentimentos em reviews de filmes.\n",
      "\n",
      "## Visão Geral\n",
      "\n",
      "O projeto utiliza o dataset \"IMDB dataset of 50k movie reviews\" disponível no Kaggle. A aplicação é construída em Python utilizando a biblioteca FastAPI para criar endpoints que permitem a predição de sentimentos (positivo ou negativo) de textos fornecidos.\n",
      "\n",
      "## Estrutura do Projeto\n",
      "\n",
      "1. **FastAPI**: Utilizada para criar a API que expõe o modelo de predição.\n",
      "2. **Scikit-learn**: Usada para criar um pipeline de machine learning que transforma texto em vetores e realiza a classificação.\n",
      "3. **Joblib**: Para salvar e carregar o modelo treinado.\n",
      "\n",
      "## Requisitos\n",
      "\n",
      "- Python 3.7+\n",
      "- Bibliotecas: FastAPI, Uvicorn, Scikit-learn, Pandas, Numpy, Joblib\n",
      "\n",
      "## Instalação\n",
      "\n",
      "1. Clone o repositório:\n",
      "   ```bash\n",
      "   git clone https://github.com/seu-usuario/fastapi-sentiment-analysis.git\n",
      "   cd fastapi-sentiment-analysis\n",
      "   ```\n",
      "\n",
      "2. Instale as dependências:\n",
      "   ```bash\n",
      "   pip install -r requirements.txt\n",
      "   ```\n",
      "\n",
      "3. Baixe o dataset do Kaggle e extraia-o na pasta do projeto.\n",
      "\n",
      "## Como Executar\n",
      "\n",
      "1. **Treinamento do Modelo**: Execute o script de treinamento para criar e salvar o modelo.\n",
      "   ```bash\n",
      "   python train_model.py\n",
      "   ```\n",
      "\n",
      "2. **Iniciar a API**: Execute o servidor FastAPI.\n",
      "   ```bash\n",
      "   uvicorn app:app --reload\n",
      "   ```\n",
      "\n",
      "3. **Testar a API**: Acesse `http://127.0.0.1:8000` no seu navegador ou use ferramentas como Postman para enviar requisições.\n",
      "\n",
      "## Importante\n",
      "\n",
      "O professor Tiago Tavares destacou um ponto crucial: **nunca faça o `.fit()` do modelo diretamente na função das queries**. Isso gera um problema de performance, pois o modelo será treinado a cada requisição, tornando o processo extremamente lento. Em vez disso, treine o modelo uma vez e salve-o. Carregue o modelo salvo quando iniciar a API.\n",
      "\n",
      "## Contribuição\n",
      "\n",
      "Sinta-se à vontade para contribuir com melhorias ou correções. Faça um fork do projeto, crie uma branch para suas alterações e envie um pull request.\n",
      "\n",
      "## Licença\n",
      "\n",
      "Este projeto está sob a licença MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.\n",
      "\n",
      "---\n",
      "\n",
      "Esperamos que este exemplo seja útil para entender como estruturar um projeto de machine learning com FastAPI e como evitar problemas comuns de performance. Se tiver dúvidas, entre em contato!\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
